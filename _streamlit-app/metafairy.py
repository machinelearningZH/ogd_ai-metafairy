import streamlit as st

st.set_page_config(layout="wide")

import time
from datetime import datetime
from dotenv import load_dotenv
import os

from openai import OpenAI
import logging

logging.basicConfig(
    filename="app.log",
    filemode="w",
    datefmt="%d-%b-%y %H:%M:%S",
    level=logging.WARNING,
)

# load_dotenv("/root/.env_stat")
load_dotenv("/Volumes/1TB Home SSD/GitHub/.env_stat")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_SYSTEM_MESSAGE = """"You are a helpful assistant."""

from utils_prompts import SYSTEM_MESSAGE_GENERATE, BASE_PROMPT_GENERATE
from utils_prompts import SYSTEM_MESSAGE_ANALYZE, BASE_PROMPT_ANALYZE
from utils_functions import parse_analysis_results, create_download_link


# ----------------------------------------------------------------


@st.cache_resource
def get_project_info():
    """Get project info."""
    with open("utils_projectinfo.md") as f:
        return f.read()


@st.cache_resource
def get_openai_client():
    return OpenAI(api_key=OPENAI_API_KEY)


def call_openai(
    prompt, modelId="gpt-4o-mini", max_tokens=4096, system_message=SYSTEM_MESSAGE_GENERATE
):
    try:
        completion = openai_client.chat.completions.create(
            model=modelId,
            temperature=0.5,
            max_tokens=max_tokens,
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt},
            ],
        )
        return True, completion.choices[0].message.content

    except Exception as e:
        print(f"Error: {e}")
        return False, None


def create_prompt_generate(
    title,
    data_content,
    data_context,
    data_quality,
    data_spatial,
):
    return f"""Schreibe eine Beschreibung f√ºr einen Datensatz. Die Metadaten des Datensatzes in Stichworten sind diese:

    Titel:\n{title}\n\n
    Dateninhalt:\n{data_content}\n\n
    Entstehungszusammenhang:\n{data_context}\n\n
    Datenqualit√§t:\n{data_quality}\n\n
    R√§umlicher Bezug:\n{data_spatial}\n\n
    {BASE_PROMPT_GENERATE}
    """


# ----------------------------------------------------------------

openai_client = get_openai_client()


# Create sidebar.
with st.sidebar:
    select_mode = st.radio(
        "W√§hle den Modus:",
        ("Beschreibung generieren", "Beschreibung analysieren"),
        index=0,
    )
    st.caption(
        "Achtung: Die App nutzt ein grosses Sprachmodell (LLM). LLMs machen Fehler. √úberpr√ºfe die generierten Analysen und Beschreibungen immer. Nutze die App nur f√ºr √∂ffentliche, nicht sensible Eingaben, da diese auf externen Rechnern des Drittanbieters OpenAI verarbeitet werden."
    )
    with st.expander("√úber diese App"):
        st.markdown(get_project_info())

# Create main content.
if select_mode == "Beschreibung generieren":
    cols = st.columns((3, 3))
    with cols[0]:
        st.subheader("üôã‚Äç‚ôÄÔ∏è Datens√§tze einfach beschreiben")

    with cols[1]:
        generate_description = st.button("**üí¨ :green[Beschreibung generieren]**")

    cols = st.columns((3, 3))

    with cols[0]:
        title = st.text_input(
            "Titel des Datensatzes", value="Verkehrsaufkommen in Z√ºrich"
        )
        data_content = st.text_area(
            ":red[**Dateninhalt**] - ***Worum geht es? Was finde ich in diesen Daten?***",
            value="Die Menge an Verkehr im Kanton Z√ºrich, gez√§hlt auf Strassen und an Kreuzungen. Inkl. Verkehrsunf√§lle, gemessener Verkehrsmittel und CO2-Belastung.",
            height=100,
        )
        data_context = st.text_area(
            ":red[**Entstehungszusammenhang**] - ***Wie wurden die Daten gemessen und wof√ºr? Was ist die Quelle?***",
            value="Kantonale Verkehrsz√§hlung, Verkehrs√ºberwachung, Verkehrsunfallstatistik. Daten gesammelt mit Kameras und Sensoren durch Polizei und Verkehrsamt.",
            height=100,
        )
        data_quality = st.text_area(
            ":red[**Datenqualit√§t**] - ***Sind die Daten vollst√§ndig? Gibt es √Ñnderungen in der Erhebung? Welche R√ºckschl√ºsse lassen sich aus den Daten ziehen und welche nicht?***",
            value="Daten aufgrund Wetter, Verkehrsdichte, Genauigkeit Sensoren nicht absolut genau. Daten wurden nur j√§hrlich erhoben. Geringf√ºgige methodische Ver√§nderungen von Jahr zu Jahr sind m√∂glich.",
            height=100,
        )
        data_spatial = st.text_area(
            "R√§umlicher Bezug - *Wie sind die Daten r√§umlich aggregiert? In welchem Gebiet sind die Datenpunkte angesiedelt?*",
            value="Kanton Z√ºrich, Genauigkeit: 10 Meter",
            height=100,
        )

    with cols[1]:
        if generate_description:
            if all([title, data_content, data_context]):
                with st.spinner("üöÄ Bin am Schreiben..."):
                    start_time = time.time()
                    prompt = create_prompt_generate(
                        title,
                        data_content,
                        data_spatial,
                        data_context,
                        data_quality,
                    )
                    success, response = call_openai(
                        prompt, system_message=SYSTEM_MESSAGE_GENERATE
                    )
                    if success:
                        response = response.replace("\n", " ")
                        response = response.replace("  ", " ")
                        st.markdown("**Generierte Beschreibung**")
                        st.markdown(f"{response}", unsafe_allow_html=True)
                        time_processed = time.time() - start_time
                        logging.warning(
                            f'{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\t{prompt}\t{response}\t{time_processed:.3f}\t{success}'
                        )
                        create_download_link(response, time_processed, title)
                        st.caption(f"Verarbeitet in {time_processed:.1f} Sekunden.")
                    else:
                        st.error(f"Es ist ein Fehler aufgetreten: {response}")
                    time_processed = time.time() - start_time
                    logging.warning(
                        f'{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\t{prompt}\t{response}\t{time_processed:.3f}\t{success}'
                    )
            else:
                st.warning("Bitte f√ºlle alle Felder aus.")
else:
    cols = st.columns((3, 3))
    with cols[0]:
        st.subheader("üôã Datens√§tze einfach analysieren")

    with cols[1]:
        generate_description = st.button("**üí¨ :green[Beschreibung analysieren]**")

    cols = st.columns((3, 3))

    with cols[0]:
        source_title = st.text_area(
            "Datensatztitel, den du analysieren willst",
            value="Anteil EFH am Wohnungsbestand [%]",
            height=68,
        )
        source_description = st.text_area(
            "Datensatzbeschreibung, die du analysieren willst",
            value="Anteil EFH am Wohnungsbestand. Wohnungsbestand gem√§ss GWS. Wohnungsbestand bis 2009 aus Fortschreibung des Wohnungsbestandes der GWZ aufgrund der WBT.",
            height=200,
        )

    with cols[1]:
        if generate_description:
            if all([source_title, source_description]):
                with st.spinner("üöÄ Bin am Analysieren..."):
                    start_time = time.time()

                    prompt = BASE_PROMPT_ANALYZE.format(
                        title=source_title, description=source_description
                    )
                    success, response = call_openai(
                        prompt, system_message=SYSTEM_MESSAGE_ANALYZE
                    )
                    if success:
                        response = parse_analysis_results(response)
                        st.caption("Dateninhalt")
                        st.markdown(response["content"].values[0])
                        st.caption("Entstehungszusammenhang")
                        st.markdown(response["context"].values[0])
                        st.caption("Datenqualit√§t")
                        st.markdown(response["quality"].values[0])
                        st.caption("R√§umlicher Bezug")
                        st.markdown(response["spacial"].values[0])
                        time_processed = time.time() - start_time
                        logging.warning(
                            f'{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\t{prompt}\t{response}\t{time_processed:.3f}\t{success}'
                        )
                        st.caption(f"Verarbeitet in {time_processed:.1f} Sekunden.")
                    else:
                        st.error(f"Es ist ein Fehler aufgetreten.")
                    time_processed = time.time() - start_time
                    logging.warning(
                        f'{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\t{prompt}\tError\t{time_processed:.3f}\t{success}'
                    )
            else:
                st.warning("Bitte f√ºlle alle Felder aus.")
